---
layout: post
title:  "DSC Complex Time Series Challenge"
date: 2015-04-05 12:00:00
author: Rohan Kotwani
excerpt: "How signal processing can be used to find seasonality in complex time-series."
tags: 
- time
- series

---

<head>

</head>

<h3>Rohan Kotwani</h3>

<p>The original problem statement was given <a href="here: http://www.datasciencecentral.com/forum/topics/challenge-of-the-week-identifying-patterns-in-complex-time-series">here</a></p>

<p>There was also a verbal solution given in the members only section. I'm not sure if its legal to share the whole thing, but here is an excerpt of the solution. " The time series has a weekly periodicity with two peaks: Monday and Thursday, corresponding respectively to the publication of the Monday and Thursday digests. The impact of the Monday and Thursday email blasts extent over the next day; this makes measuring the yield more difficult, unless you use additional data, e.g. from our newsletter vendor. However, the bulk of the impact is really on Monday and Thursday."</p>

<p>There are a variety of signal processing techniques that can be applied to time series data. For example, trend components can be extracted from a time series by transforming the signal into the frequency domain, filtering out non dominant frequencies, and then recombining the signal. This tends to work well for finding the overall trend, but it violates the assumption that the signal is a stationary process. In addition, this method is limited to the shapes that the sum of orthogonal sinusoids can make. This paper considers another approach where dominant frequencies are extracted, but where the signals are recombined in a linear model. In this linear model, the seasonality of the time series can be accounted by including a set of orthogonal sinusoidal waves, different frequencies, and different time components. However, finding the appropriate frequency and time component for each sinusoid requires a little more digging. This paper shows how to use Discrete Fourier transforms to automatically find these values.</p>

<h3>Signal Processing Basics</h3>

<p><img src='/ts_challenge_images/n_point_DFT.tiff' /></p>

<ul>
<li>k ? [0,N-1] or k ? [?N/2, N/2?1] or k ? [?(N?1)/2, (N?1)/2]</li>
<li>N = # of data points</li>
<li>n = rank order of input data points</li>
<li>k = rank order of output data points</li>
</ul>

<h3>Assumptions</h3>

<p>"The Fourier transform assumes that the signal is stationary and that the signals in the sample continue into infinity. The Fourier transform performs poorly when this is not the case."</p>

<p>A stationary process has a constant mean and variance over time which is a property that most time series don't have. A stationary process can be extracted from the time series by creating a time differenced variable. However, the complex magnitudes from the time difference variable does not represent the actual signal. A regression model can then be used to recontruct the magnitudes of this signal.</p>

<h3>Model Definition</h3>

<p>y = T(t) + S(t) + R(t)<p>

<ul>
<li>T(t)~Trend component</li>
<li>S(t)~Seasonal component</li>
<li>R(t)~Residual error</li>
</ul>

<p>Objective function: minimize sum of squared errors</p>

<p>Closed form, least squared solution (Python code):</p>

<pre style='color:#000000;background:#ffffff;'><span style='color:#7f0055; font-weight:bold; '>import</span> numpy <span style='color:#7f0055; font-weight:bold; '>as</span> np
A=x.T.dot(x) <span style='color:#3f7f59; '># x = intercept + predictor columns</span>
b=x.T.dot(y) <span style='color:#3f7f59; '># y = target variable</span>
z = np.linalg.solve(A,b)
</pre>


<p>This works perfectly for a dataset with a smaller number of non-collinear dimensions. However, the numpy algorithm can break with a dataset that has many collinear dimensions.</p>

<p>For the purposes of this post, we will only focus on the T(t) and S(t) components. 80% of the data or 584 observations were used to create the training set. The model was validated on the remaining 146 observations.</p>

<pre style='color:#000000;background:#ffffff;'><span style='color:#7f0055; font-weight:bold; '>import</span> pandas <span style='color:#7f0055; font-weight:bold; '>as</span> pd
<span style='color:#7f0055; font-weight:bold; '>import</span> numpy <span style='color:#7f0055; font-weight:bold; '>as</span> np
<span style='color:#7f0055; font-weight:bold; '>import</span> matplotlib.pyplot <span style='color:#7f0055; font-weight:bold; '>as</span> plt
<span style='color:#7f0055; font-weight:bold; '>import</span> datetime

full=pd.read_csv(<span style='color:#2a00ff; '>"DATA/DSC_Time_Series_Challenge.csv"</span>,dtype = {<span style='color:#2a00ff; '>'Day '</span>:<span style='color:#7f0055; font-weight:bold; '>str</span>,<span style='color:#2a00ff; '>'Sessions'</span>:<span style='color:#7f0055; font-weight:bold; '>int</span>,<span style='color:#2a00ff; '>'Pageviews'</span>:<span style='color:#7f0055; font-weight:bold; '>int</span>})
time=[datetime.datetime.strptime(t[0],<span style='color:#2a00ff; '>"%m/%d/%y"</span>) <span style='color:#7f0055; font-weight:bold; '>for</span> t <span style='color:#7f0055; font-weight:bold; '>in</span> full[[<span style='color:#2a00ff; '>'Day '</span>]].values]
weekday=[datetime.datetime.strptime(t[0],<span style='color:#2a00ff; '>"%m/%d/%y"</span>).isocalendar()[2] <span style='color:#7f0055; font-weight:bold; '>for</span> t <span style='color:#7f0055; font-weight:bold; '>in</span> full[[<span style='color:#2a00ff; '>'Day '</span>]].values]

full[<span style='color:#2a00ff; '>'time'</span>]=time
full[<span style='color:#2a00ff; '>'index'</span>]=np.arange(1,<span style='color:#7f0055; font-weight:bold; '>len</span>(full)+1)
full[<span style='color:#2a00ff; '>'weekday'</span>]=weekday
full=full.sort_values(by=[<span style='color:#2a00ff; '>'time'</span>])

plt.plot(full[<span style='color:#2a00ff; '>'index'</span>],full[<span style='color:#2a00ff; '>'Pageviews'</span>],<span style='color:#2a00ff; '>'-'</span>)
plt.xlabel(<span style='color:#2a00ff; '>'time'</span>)
plt.ylabel(<span style='color:#2a00ff; '>'Pageviews'</span>)
plt.title(<span style='color:#2a00ff; '>'Pageviews'</span>)
plt.show()
</pre>

<p><img src='/ts_challenge_images/output_1_0.png' /></p>

<pre style='color:#000000;background:#ffffff;'>train=full[:580].copy()
valid=full[580:].copy()
train.head(n=5)
</pre>


<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Day</th>
      <th>Sessions</th>
      <th>Pageviews</th>
      <th>time</th>
      <th>index</th>
      <th>weekday</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9/25/13</td>
      <td>4370</td>
      <td>7177</td>
      <td>2013-09-25</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9/26/13</td>
      <td>5568</td>
      <td>10760</td>
      <td>2013-09-26</td>
      <td>2</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9/27/13</td>
      <td>4321</td>
      <td>8171</td>
      <td>2013-09-27</td>
      <td>3</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9/28/13</td>
      <td>2378</td>
      <td>4093</td>
      <td>2013-09-28</td>
      <td>4</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9/29/13</td>
      <td>2612</td>
      <td>4881</td>
      <td>2013-09-29</td>
      <td>5</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>


<p>The weekday variable will be dummy coded and used later to compare results</p>

<pre style='color:#000000;background:#ffffff;'>weekday_dummies = pd.get_dummies(train.weekday, prefix=<span style='color:#2a00ff; '>'W'</span>).iloc[:, 1:]
train = pd.concat([train, weekday_dummies], axis=1)
weekday_dummies = pd.get_dummies(valid.weekday, prefix=<span style='color:#2a00ff; '>'W'</span>).iloc[:, 1:]
valid = pd.concat([valid, weekday_dummies], axis=1)
</pre>

<pre style='color:#000000;background:#ffffff;'>
import Regression
import DSP</pre>

<h3>Finding the overall trend:</h3>

<p>A polynomial term can be used to represent the trend component T(t) which can be created from the index variable. The complexity of the trend component can be tuned by using a training and validation set to find optimal complexity with the lowest sum of squared errors. A complexity of degree 2 had the lowest SSE value on the validation set so these terms will be included in the model.</p>

<pre style='color:#000000;background:#ffffff;'>heap = []
<span style='color:#7f0055; font-weight:bold; '>for</span> i <span style='color:#7f0055; font-weight:bold; '>in</span> <span style='color:#7f0055; font-weight:bold; '>range</span>(1,15):
    z=Regression.sklearn_poly_regression(train[[<span style='color:#2a00ff; '>'index'</span>]],train[[<span style='color:#2a00ff; '>'Pageviews'</span>]],i)
    SSE = Regression.numpy_poly_regression_SSE(valid[[<span style='color:#2a00ff; '>'index'</span>]],valid[[<span style='color:#2a00ff; '>'Pageviews'</span>]],i,z)
    heap.append((SSE,i))
Regression.heapsort(heap)
</pre>



<pre>
    [(2501666772.2010365, 2),
     (2699152210.1621375, 9),
     (2699503808.6114817, 14),
     (2701796858.0785437, 10),
     (2701846050.0146337, 13),
     (2702552306.8232799, 12),
     (2706108691.5368271, 11),
     (2990342895.3898125, 8),
     (4491840385.0665913, 1),
     (4868690323.6375523, 4),
     (5963871838.3020554, 3),
     (11208662852.721825, 5),
     (317581251234.68689, 7),
     (477442016671.72321, 6)]
 </pre>

<pre style='color:#000000;background:#ffffff;'>T_train = Regression.pandas_poly_feature(train[[<span style='color:#2a00ff; '>'index'</span>]],2)
T_valid = Regression.pandas_poly_feature(valid[[<span style='color:#2a00ff; '>'index'</span>]],2)
</pre>

<h3>Removing the overall trend:</h3>

<p>First, the overall trend needs to be removed from the signal in order to statisfy the stationary process assumption. This can be accomplished by creating a lag 1 differenced variable for Pageviews. This differenced variable will also make seasonal components easier to find.</p>

<pre style='color:#000000;background:#ffffff;'>time_diff_signal = DSP.time_diff_variable(train[<span style='color:#2a00ff; '>'Pageviews'</span>],1)
plt.plot(train[<span style='color:#2a00ff; '>'index'</span>][1:],time_diff_signal,<span style='color:#2a00ff; '>'-'</span>)
plt.xlabel(<span style='color:#2a00ff; '>'time'</span>)
plt.ylabel(<span style='color:#2a00ff; '>'Pageviews[t] - Pageviews[t-1]'</span>)
plt.title(<span style='color:#2a00ff; '>'Pageviews[t] - Pageviews[t-1]'</span>)
plt.show()
</pre>
<!--Created using ToHtml.com on 2019-01-15 03:09:20 UTC -->

<p><img src='/ts_challenge_images/output_11_0.png' /></p>

<h3>The FFT transformation:</h3>

<p>Taking the FFT of the time differenced signal creates a complex magnitude representation for each sinusoidal frequency component in the signal.</p>

<p>The data is filtered to include only the dominant sinusodial frequency components. Usually, the complex magnitude can be used to find the phase and absolute magnitude of the sinusodial wave corresponding to each frequency. In this case, we are using a time difference variable so the magnitudes and phases are not representative of the actual variable.</p>

<p>This process can be semi-automated by using statistics. The center frequency can be found by average across all frequencies. The bandwidth of the filter can be defined by frequencies within to standard deviations of the mean of the absolute complex magnitude. The purpose of this is avoid periods that are too large.</p>

<pre style='color:#000000;background:#ffffff;'>N = <span style='color:#7f0055; font-weight:bold; '>len</span>(time_diff_signal)
unfiltered  = DSP.get_frequency_domain(time_diff_signal)
y_abs=( 2.0/N * np.<span style='color:#7f0055; font-weight:bold; '>abs</span>(unfiltered[1:,1]))

center = np.mean(unfiltered[1:,0])
band = 1*np.std(unfiltered[1:,0])
threshold = np.mean(y_abs)+1*np.std(y_abs)

<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Center frequency: "</span>,np.<span style='color:#7f0055; font-weight:bold; '>abs</span>(center),<span style='color:#2a00ff; '>"Band: "</span>,np.absolute(band),<span style='color:#2a00ff; '>"Threshold: "</span>,threshold)

plt.plot(unfiltered[1:,0],y_abs)
plt.xlabel(<span style='color:#2a00ff; '>'frequency'</span>)
plt.ylabel(<span style='color:#2a00ff; '>'absolute magnitude'</span>)
plt.title(<span style='color:#2a00ff; '>"Absolute Magnitude of Complex Frequencies"</span>)
plt.show()

<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Frequency, Magnitude"</span>)
abs_filtered = np.absolute(DSP.filter_freq_domain(unfiltered, center,band,threshold))
<span style='color:#7f0055; font-weight:bold; '>print</span>(abs_filtered)
</pre>
<!--Created using ToHtml.com on 2019-01-15 03:10:20 UTC -->

<pre>
Center frequency:  0.249568221071 Band:  0.14358883867 Threshold:  408.870795735
</pre>

<p><img src='/ts_challenge_images/output_13_2.png' /></p>

<pre>
    Frequency, Magnitude
    [[  1.41623489e-01   1.33800535e+05]
     [  1.43350604e-01   4.90313504e+05]
     [  2.78065630e-01   1.31154698e+05]
     [  2.81519862e-01   1.23147724e+05]
     [  2.83246978e-01   2.54959357e+05]
     [  2.84974093e-01   6.93085781e+05]
     [  2.86701209e-01   5.95979105e+05]
     [  2.88428325e-01   1.80149377e+05]
     [  2.90155440e-01   1.44095857e+05]
     [  2.91882556e-01   1.36036705e+05]]
</pre>

<h3>Creating seasonal predictor variables</h3>

<p>After filtering the data, the dominant frequencies were found at .143, .28, and .29. These correspond to T=7,4, and 3, respectively. Sequences with these periods can be created.</p>

<p>Notice that the frequency .428, that corresponds to a period of 2 (actually a little below), was not included in our predictors. This is because of Nyquist's thoeorm:</p>

<p>"When the signal bandlimited to ? fs cycles/second (hertz), its Fourier transform, X(f), is 0 for all |f| > 1/2*(1/T)"</p>
<p>In this case the signal has a sampling period of 1 or a sampling frequency of 1. The maximum frequency we can "see," by Nyquist's theorm, would be a signal with a period greater than 2.</p>

<pre style='color:#000000;background:#ffffff;'>period_list = <span style='color:#7f0055; font-weight:bold; '>set</span>([<span style='color:#7f0055; font-weight:bold; '>round</span>(1/(ft)) <span style='color:#7f0055; font-weight:bold; '>for</span> ft,ht <span style='color:#7f0055; font-weight:bold; '>in</span> abs_filtered <span style='color:#7f0055; font-weight:bold; '>if</span> <span style='color:#7f0055; font-weight:bold; '>round</span>(1/(ft))>2])
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Sequence list: "</span>,period_list)

train = DSP.get_sequences(train,period_list,start_index=1,plot=True)
valid = DSP.get_sequences(valid,period_list,start_index=<span style='color:#7f0055; font-weight:bold; '>len</span>(train)+1,plot=False)
valid.head()
</pre>
<!--Created using ToHtml.com on 2019-01-15 03:12:28 UTC -->
<pre style='color:#000000;background:#ffffff;'>
Sequence list:  {3.0, 4.0, 7.0}
</pre>

<p><img src='/ts_challenge_images/output_15_2.png' /></p>
<p><img src='/ts_challenge_images/output_15_3.png' /></p>
<p><img src='/ts_challenge_images/output_15_4.png' /></p>


<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Day</th>
      <th>Sessions</th>
      <th>Pageviews</th>
      <th>time</th>
      <th>index</th>
      <th>weekday</th>
      <th>W_2</th>
      <th>W_3</th>
      <th>W_4</th>
      <th>W_5</th>
      <th>W_6</th>
      <th>W_7</th>
      <th>seq_3.0</th>
      <th>seq_4.0</th>
      <th>seq_7.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>580</th>
      <td>4/28/15</td>
      <td>13162</td>
      <td>19757</td>
      <td>2015-04-28</td>
      <td>581</td>
      <td>2</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>581</th>
      <td>4/29/15</td>
      <td>12395</td>
      <td>18568</td>
      <td>2015-04-29</td>
      <td>582</td>
      <td>3</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>582</th>
      <td>4/30/15</td>
      <td>12351</td>
      <td>19122</td>
      <td>2015-04-30</td>
      <td>583</td>
      <td>4</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>583</th>
      <td>5/1/15</td>
      <td>12301</td>
      <td>19830</td>
      <td>2015-05-01</td>
      <td>584</td>
      <td>5</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>584</th>
      <td>5/2/15</td>
      <td>9345</td>
      <td>14110</td>
      <td>2015-05-02</td>
      <td>585</td>
      <td>6</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>4.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Eureka! Weekday (Sequence period = 7) shares the same frequency components as Pageviews!</p>
<p>The table below shows the index and weekday to help illustrate what the periods or cycles. The index starts at 1, but this corresponds to weekday 3 (or Wednesday). So index 6 corresponds to Monday and index 2 corresponds to Thursday.</p>

<h3>Fitting the Model</h3>

<p>Since T(t) is already created, this part of the blog will focus on S(t).</p>
<p>Each generated sequence will be made into pairs of seasonable components and will have at least two components, two sinusoidal waves, i.e. ?1sin(t/T) + ?2cos(t/T). In fact, the sum of weighted cosine & sine terms for each dominant frequency in the signal can be thought of as a Fourier Series. The difference is that the ? valus will only be estimated for the most dominant frequenciesinstead of an infinite, or large number of periodic waves.</p>
<p>Fourier series formula</p>

<p><img src='/ts_challenge_images/Fourier_Series_formula-1.tiff' /></p>

<p>How is this done automatically?</p>
<p>Consider an example where there exists a periodic signal of period 13 inside of the main signal.</p>
<p>Seasonal components are generated automatically by first creating a saw tooth wave with a period of 13. This series represent the time component of a series of sinusoids with various periods. But how do we choose these periods? The saw tooth wave is unique in that each level appears only once in each period. By taking the FFT of this wave, the frequencies of this wave show how many sinusoids are needed to represent the wave at each unique level. By selecting the dominany freuquencies of this wave, a variery of shapes can be create for the seasonal component of period 13. This is accomplished by summing a set of orthogonal sine waves, with different periods, which use the save tooth wave as the time component. The saw tooth wave is used at the time component to force the resultant wave to have a period of 13.</p>
<p>Sum of Cosines = β1sin(2*π*x/13) + β2cos(2*π*x/7) + β3cos(2*π*x/4) + β4cos(2*π*x/3) + β5cos(2*π*x/2) , 0 <= x < 13</p>

<pre style='color:#000000;background:#ffffff;'>output=train[[<span style='color:#2a00ff; '>'Pageviews'</span>]]
y=output.values

m,n =np.shape(output)
count=0


S_train = np.ones((<span style='color:#7f0055; font-weight:bold; '>len</span>(train),1))
S_valid = np.ones((<span style='color:#7f0055; font-weight:bold; '>len</span>(valid),1))

<span style='color:#7f0055; font-weight:bold; '>for</span> component <span style='color:#7f0055; font-weight:bold; '>in</span> period_list:
    f=DSP.get_sequence_freq(var=train[[<span style='color:#2a00ff; '>"seq_"</span>+<span style='color:#7f0055; font-weight:bold; '>str</span>(component)]],std_thresh=3,plot=True)
    x=DSP.get_seasonal_predictors(train[[<span style='color:#2a00ff; '>"seq_"</span>+<span style='color:#7f0055; font-weight:bold; '>str</span>(component)]],f)
    S_train=np.column_stack((S_train,x))
    x=DSP.get_seasonal_predictors(valid[[<span style='color:#2a00ff; '>"seq_"</span>+<span style='color:#7f0055; font-weight:bold; '>str</span>(component)]],f)
    S_valid=np.column_stack((S_valid,x))
    count+=1
plt.plot(train[<span style='color:#2a00ff; '>'index'</span>][:60],train[<span style='color:#2a00ff; '>'Pageviews'</span>][:60],<span style='color:#2a00ff; '>'-'</span>)
plt.xlabel(<span style='color:#2a00ff; '>"time"</span>)
plt.ylabel(<span style='color:#2a00ff; '>"Pageviews"</span>)
plt.title(<span style='color:#2a00ff; '>"Pageviews"</span>)
plt.show()

x=S_train

A=x.T.dot(x)
b=x.T.dot(y)
z = np.linalg.solve(A,b)

SSE=np.<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-x.dot(z))**2)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SSE :"</span>,SSE)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Baseline: "</span>,<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0])

<span style='color:#3f7f59; '># plt.plot(train['index'],y,'.') </span>
plt.plot(train[<span style='color:#2a00ff; '>'index'</span>][:60],x.dot(z)[:60],<span style='color:#2a00ff; '>'-'</span>)
plt.title(<span style='color:#2a00ff; '>"Weighted Addition of Seasonal Components"</span>)
plt.xlabel(<span style='color:#2a00ff; '>"time"</span>)
plt.ylabel(<span style='color:#2a00ff; '>"predicted value"</span>)
plt.show()
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"coefficients: "</span>)
<span style='color:#7f0055; font-weight:bold; '>print</span>(z)
</pre>

<pre>
    threshold 0.213708597747
    frequencies  [[  0.00000000e+00   5.80000000e+02]
     [  3.31034483e-01   6.86580342e+01]
     [  3.32758621e-01   2.76353001e+02]
     [  3.34482759e-01   1.39043662e+02]]</pre>

<p><img src='/ts_challenge_images/output_18_2.png' /></p>

<pre>     
    frequencies used in  seq_3.0  :  [0.33333333333333331]
    frequencies used in  seq_3.0  :  [0.33333333333333331]
    threshold 0.254028420631
    frequencies  [[  0.00000000e+00   8.70000000e+02]
     [  2.50000000e-01   4.10121933e+02]]</pre>
     
<p><img src='/ts_challenge_images/output_18_4.png' /></p>
     
<pre>      
    frequencies used in  seq_4.0  :  [0.25]
    frequencies used in  seq_4.0  :  [0.25]
    threshold 0.525113865983
    frequencies  [[  0.00000000e+00   1.74300000e+03]
     [  1.43103448e-01   6.45133516e+02]
     [  2.86206897e-01   3.22688369e+02]
     [  4.27586207e-01   1.61660579e+02]
     [  4.29310345e-01   2.15278734e+02]]</pre>
     
<p><img src='/ts_challenge_images/output_18_6.png' /></p>

<pre>    
    frequencies used in  seq_7.0  :  [0.14285714285714285, 0.5, 0.33333333333333331]
    frequencies used in  seq_7.0  :  [0.14285714285714285, 0.5, 0.33333333333333331]
</pre>

<p><img src='/ts_challenge_images/output_18_8.png' /></p>

<pre>   
    SSE : 5765825922.99
    Baseline:  8530795814.65</pre>
    
<p><img src='/ts_challenge_images/output_18_10.png' /></p>

<pre>    
        coefficients: 
    [[  1.06306549e+04]
     [ -1.63450638e+00]
     [  5.94252422e+01]
     [ -6.20595993e+01]
     [ -3.09144366e+00]
     [  1.29084218e+03]
     [ -5.98934835e+18]
     [ -2.34003768e+03]
     [  1.42249877e+03]
     [ -1.72123723e+03]
     [  1.13494916e+03]]</pre>
     
     
<h3>Weighted Addition of Seasonal Components</h3>
<p>In the regression model, each of these components will get a weight associated with it which can be added together to create a weighted seasonal component. The weighted seasonal component has a pattern similar to that of the Pageviews. </p>
<h3>Seasonal Predictors</h3>
<p>There are 3 saw tooth sequences included in the model each with a unique t, time index. A saw tooth of period 3 & 4 have only two sinusoids with with periods 0.33 & 0.25, respectively. Finally, a saw tooth wave of period 7 is used inside of 6 sinusoids with periods 0.1428, 0.333, and 0.5.</p>
<p>These periods can be found using the same semi-automated techniques used to generate the sequences as described earlier. The threshold can be adjust by the number of standard deviations from the mean of the absolute complex magnitude.</p>
<h3>Finding peaks</h3>
<p>There are two peaks which correspond to Monday and Thursday. This is consistent with the problem solution given above.</p>


<pre style='color:#000000;background:#ffffff;'>peaks=[]
<span style='color:#7f0055; font-weight:bold; '>for</span> i,xz <span style='color:#7f0055; font-weight:bold; '>in</span> <span style='color:#7f0055; font-weight:bold; '>enumerate</span>(x.dot(z)):
    <span style='color:#7f0055; font-weight:bold; '>if</span> i>0 <span style='color:#7f0055; font-weight:bold; '>and</span> i&lt;<span style='color:#7f0055; font-weight:bold; '>len</span>(x.dot(z))-1:
        <span style='color:#7f0055; font-weight:bold; '>if</span> x.dot(z)[i]>x.dot(z)[i-1] <span style='color:#7f0055; font-weight:bold; '>and</span> x.dot(z)[i]>x.dot(z)[i+1]:
            peaks.append(train[<span style='color:#2a00ff; '>'time'</span>][i].isocalendar()[2])
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#7f0055; font-weight:bold; '>set</span>(peaks))
</pre>
<!--Created using ToHtml.com on 2019-01-15 03:18:58 UTC -->

<pre>
    {1, 4}
</pre>

<h3>Training & Validation</h3>
<p>The following models will be trained and validated with different seasonal variables:</p>
<p>1. Model fitted with a dummy coded weekday variable</p>
<p>2. Model fitted with extracted sinusodial components</p>


<pre style='color:#000000;background:#ffffff;'>y=train[[<span style='color:#2a00ff; '>'Pageviews'</span>]].values

m =<span style='color:#7f0055; font-weight:bold; '>len</span>(train)

x=np.ones((m,9))
x[:,1:]=np.column_stack((train[<span style='color:#2a00ff; '>'W_2'</span>],train[<span style='color:#2a00ff; '>'W_3'</span>],
                         train[<span style='color:#2a00ff; '>'W_4'</span>],train[<span style='color:#2a00ff; '>'W_5'</span>],train[<span style='color:#2a00ff; '>'W_6'</span>],
                         train[<span style='color:#2a00ff; '>'W_7'</span>],T_train))


A=x.T.dot(x)
b=x.T.dot(y)
z = np.linalg.solve(A,b)

SSE=np.<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-x.dot(z))**2)
SST=<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0]
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Training"</span>)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SSE: "</span>,SSE)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SST: "</span>,SST)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"R^2: "</span>,1-SSE/SST)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Baseline: "</span>,<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0])

plt.plot(train[<span style='color:#2a00ff; '>'index'</span>],y,<span style='color:#2a00ff; '>'.'</span>)
plt.plot(train[<span style='color:#2a00ff; '>'index'</span>],x.dot(z),<span style='color:#2a00ff; '>'-'</span>)
plt.title(<span style='color:#2a00ff; '>"Dummy coded weekday variable: Training"</span>)
plt.show()

plt.scatter(train[<span style='color:#2a00ff; '>'index'</span>],y-x.dot(z))
plt.title(<span style='color:#2a00ff; '>"Residuals"</span>)
plt.show()
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"coefficients:"</span>)
<span style='color:#7f0055; font-weight:bold; '>print</span>(z)
<span style='color:#7f0055; font-weight:bold; '>print</span>()

y=valid[[<span style='color:#2a00ff; '>'Pageviews'</span>]].values

m =<span style='color:#7f0055; font-weight:bold; '>len</span>(valid)

x=np.ones((m,9))
x[:,1:]=np.column_stack((valid[<span style='color:#2a00ff; '>'W_2'</span>],valid[<span style='color:#2a00ff; '>'W_3'</span>],
                         valid[<span style='color:#2a00ff; '>'W_4'</span>],valid[<span style='color:#2a00ff; '>'W_5'</span>],valid[<span style='color:#2a00ff; '>'W_6'</span>],
                         valid[<span style='color:#2a00ff; '>'W_7'</span>],T_valid))



SSE=np.<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-x.dot(z))**2)
SST=<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0]
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Validation"</span>)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SSE: "</span>,SSE)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SST: "</span>,SST)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"R^2: "</span>,1-SSE/SST)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Baseline: "</span>,<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0])

plt.plot(valid[<span style='color:#2a00ff; '>'index'</span>],valid[[<span style='color:#2a00ff; '>'Pageviews'</span>]],<span style='color:#2a00ff; '>'.'</span>)
plt.plot(valid[<span style='color:#2a00ff; '>'index'</span>],x.dot(z),<span style='color:#2a00ff; '>'-'</span>)
plt.title(<span style='color:#2a00ff; '>"Dummy coded weekday variable: Validation"</span>)
plt.show()

plt.scatter(valid[<span style='color:#2a00ff; '>'index'</span>],y-x.dot(z))
plt.title(<span style='color:#2a00ff; '>"Residuals"</span>)
plt.show()
</pre>
<!--Created using ToHtml.com on 2019-01-15 03:19:45 UTC -->

<pre>
    Training
    SSE:  1912154025.09
    SST:  8530795814.65
    R^2:  0.775852796546
    Baseline:  8530795814.65
    </pre>
    

<p><img src='/ts_challenge_images/output_23_1.png' /></p>

<p><img src='/ts_challenge_images/output_23_2.png' /></p>

<pre>
    coefficients:
    [[  1.15385953e+04]
     [ -2.79933336e+03]
     [ -3.32862564e+03]
     [ -1.48611482e+03]
     [ -3.71268360e+03]
     [ -6.88505486e+03]
     [ -5.73875872e+03]
     [ -1.29164524e+00]
     [  2.77465319e-02]]
    
    Validation
    SSE:  1159104596.32
    SST:  2424981317.62
    R^2:  0.522015040734
    Baseline:  2424981317.62
</pre>

<p><img src='/ts_challenge_images/output_23_4.png' /></p>

<p><img src='/ts_challenge_images/output_23_5.png' /></p>


<p>The regression model on the training dataset had an R-Squared value of 0.78 with 9 predictor variables. The residual are evenly distributed around zero with a two large outliers.</p>
<p>The validation dataset had an R-Squared of 0.52. The validation dataset residuals have many outliers compared the the training dataset residuals. In addition, there is a slight downward trend which suggests that a variable might be left out of the model.</p>

<pre style='color:#000000;background:#ffffff;'>y=train[[<span style='color:#2a00ff; '>'Pageviews'</span>]].values

x=np.column_stack((S_train,T_train))


A=x.T.dot(x)
b=x.T.dot(y)
z = np.linalg.solve(A,b)

SSE=np.<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-x.dot(z))**2)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SSE :"</span>,SSE)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Baseline: "</span>,<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2))


SSE=np.<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-x.dot(z))**2)
SST=<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0]
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SSE: "</span>,SSE)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SST: "</span>,SST)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"R^2: "</span>,1-SSE/SST)


plt.plot(train[<span style='color:#2a00ff; '>'index'</span>],y,<span style='color:#2a00ff; '>'.'</span>)
plt.plot(train[<span style='color:#2a00ff; '>'index'</span>],x.dot(z),<span style='color:#2a00ff; '>'-'</span>)
plt.title(<span style='color:#2a00ff; '>"Seasonally predicted Values over time: Training"</span>)
plt.show()

plt.scatter(train[<span style='color:#2a00ff; '>'index'</span>],y-x.dot(z))
plt.title(<span style='color:#2a00ff; '>"Residuals"</span>)
plt.show()


<span style='color:#7f0055; font-weight:bold; '>print</span>(z)
<span style='color:#7f0055; font-weight:bold; '>print</span>()


output=valid[[<span style='color:#2a00ff; '>'Pageviews'</span>]]
y=output.values


x=np.column_stack((S_valid,T_valid))

SSE=np.<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-x.dot(z))**2)
SST=<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0]

<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SSE: "</span>,SSE)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"SST: "</span>,SST)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"R^2: "</span>,1-SSE/SST)
<span style='color:#7f0055; font-weight:bold; '>print</span>(<span style='color:#2a00ff; '>"Baseline: "</span>,<span style='color:#7f0055; font-weight:bold; '>sum</span>((y-np.mean(y))**2)[0])

plt.plot(valid[<span style='color:#2a00ff; '>'index'</span>],y,<span style='color:#2a00ff; '>'.'</span>)
plt.plot(valid[<span style='color:#2a00ff; '>'index'</span>],x.dot(z),<span style='color:#2a00ff; '>'-'</span>)
plt.title(<span style='color:#2a00ff; '>"Seasonally predicted Values over time"</span>)
plt.show()
plt.scatter(valid[<span style='color:#2a00ff; '>'index'</span>],y-x.dot(z))
plt.title(<span style='color:#2a00ff; '>"Residuals"</span>)
plt.show()
</pre>
<!--Created using ToHtml.com on 2019-01-15 03:20:55 UTC -->

<p><img src='/ts_challenge_images/output_25_1.png' /></p>

<p><img src='/ts_challenge_images/output_25_2.png' /></p>

<pre>
    SSE : 1910499966.56
    Baseline:  [  8.53079581e+09]
    SSE:  1910499966.56
    SST:  8530795814.65
    R^2:  0.776046689187
</pre>

<p><img src='/ts_challenge_images/output_25_4.png' /></p>

<p><img src='/ts_challenge_images/output_25_5.png' /></p>

[[  7.88822225e+03]
 [ -1.04772341e+01]
 [  5.49537731e+01]
 [ -4.71633832e+01]
 [ -1.78556064e+01]
 [  1.31883444e+03]
 [ -5.94631183e+18]
 [ -2.32539453e+03]
 [  1.42930303e+03]
 [ -1.70801754e+03]
 [  1.13000291e+03]
 [ -1.29585954e+00]
 [  2.77521502e-02]]

<pre>
    SSE:  1160469260.63
    SST:  2424981317.62
    R^2:  0.521452288231
    Baseline:  2424981317.62
</pre>

<h3>Results</h3>
<p>The regression model on the training dataset had an R-Squared value of 0.78 with 9 predictor variables. The residual are evenly distributed around zero with a two large outliers. </p>
<p>The validation dataset had an R-Squared of 0.52. The validation dataset residuals have many outliers compared the the training dataset residuals. In addition, there is a slight downward trend which suggests that a variable might be left out of the model.</p>
<p>The results are almost (if not) exactly the same, so which method to choose?</p>
<p>Dummy coding can be automated, but its not always easy to type every variable to include in a linear model. In addition, it requires some inpection and trail and error to find the seasonal variable. The advantage of dummy coding is that each level is accounted for and it relatively easy to compare levels.</p>
<p>Signal processing can be used to create seasonal components almost automatically, but it is more computational expensive to calculate. In addition, it is not clear from the coefficients what the seasonal components are. The advantage is that there can be more predictive variables in the model, and the number of sinusodial components can be increased or decreased by adjusting the threshold or bandwith. </p>
