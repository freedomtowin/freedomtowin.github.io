---
layout: post
title: "Deep Autoregressive Models"
date: 2020-05-12 12:00:00
author: Rohan Kotwani
excerpt: "Forecasting with TensorFlow 2.0"
tags: 
- time
- series
---

<head>

</head>

<h3>Rohan Kotwani</h3>

<div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="e047" class="graf graf--h3 graf--leading graf--title">Forecasting with TensorFlow 2.0</h3><p name="daad" class="graf graf--p graf-after--h4 is-selected">Business-related time series are often non-continuous, or discrete, time-based processes. Operationally, it might be useful for businesses to know, or to be able to quantify when a time series will be at a peak or trough in the future. The goal is to capture the trend and periodic patterns and to forecast the signal for >1 samples into the future. The example notebook is available in the TensorFlow Formulation section of this article.</p><h4 name="61e9" class="graf graf--h4 graf-after--p">Trend, Periodicity, and&nbsp;Noise</h4><p name="8b98" class="graf graf--p graf-after--h4">n most business-related applications, the time series have non-constant mean and variance over time, or they can be said to be <em class="markup--em markup--p-em">non-stationary</em>. This is contrasted to stationary signals and systems used in the analysis of electrical circuits, audio engineering, and communication systems. The direction in which the mean value changes indicates the <strong class="markup--strong markup--p-strong">trend</strong> of the time series. The variation of the <strong class="markup--strong markup--p-strong">noise </strong>could be a function of some random process. The noise can potentially increase or decrease as a function of time.</p><p name="a38e" class="graf graf--p graf-after--p">There is a granularity <em class="markup--em markup--p-em">time limit</em> to the which <strong class="markup--strong markup--p-strong">periodic</strong>, or recurring,<strong class="markup--strong markup--p-strong"> </strong>patterns can be captured. In digital signal processing, the <a href="https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FNyquist_rate" data-href="https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FNyquist_rate" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener noopener noopener noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FNyquist_rate" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">Nyquist rate</a> is the minimum sampling period required to capture a pattern that reoccurs with period N. Essentially, the sampling rate needs to be less than half of one cycle of the recurring pattern. For example, let us say there is a feature in the data that measures the number of sales every 6 hours. The most granular pattern that can be captured will be one that reoccurs every 12 hours.</p>
    
    <h3 name="8c72" class="graf graf--h3 graf-after--p">Autoregressive Model Formulation</h3>
    
    <p name="0e00" class="graf graf--p graf-after--h3">Autoregressive models and open loop feedback systems, a type of control system, have some similarities. Both of these systems depend on the previous output of the model. We would like both of these systems to be stable, i.e., not explode into an exponential output. These systems are different in that autoregressive forecasts can depend on multiple lagged input features. The form of the autoregressive model is shown in equation (0).</p>
    
    
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*MjtKvq75C2PROiMWVKM8IA.png" /> <figcaption></figcaption></figure>
    
    
    <p name="2aa5" class="graf graf--p graf-after--figure">Where T is number of lagged features, w represents the autoregressive weights, y(t-i) represents the lagged time series, and y*(t+1) is the predicted value at t+1.</p>

    <p name="bb22" class="graf graf--p graf-after--p is-selected">The goal is to create a linearized form of the autoregressive model using the 1st order <a href="https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FTaylor_series" data-href="https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FTaylor_series" class="markup--anchor markup--p-anchor" rel="noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FTaylor_series" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">Taylor Series</a> approximation. The autoregressive formula is recursive, meaning the next value depends on a cascade of the previous values. The value at y(t+1) is estimated with Taylor Series expansion of f(t+1) around time step t. Equation (2) shows the estimated value for y(t+1) using the 1st order Taylor Series approximation. Note, that the -1 constant, on the right hand side of equation (2), will be absorbed by the weights.</p>
    
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*8NubH1EmU_qQX3FgLD-2GA.png" /> <figcaption></figcaption></figure>
    
    <p name="164b" class="graf graf--p graf-after--figure is-selected">Where f(t) is a recursive dense layer which represents y(t) with some error term, y* is the predicted output, w_t are the weights, and T is number of lagged features. Equation (3) shows the Taylor Series expansion for the simple case where y(t+1) depends on the previous value of f(t+1).The reason why I used f(t), in equation (2), instead of using y(t) directly is because y(t) represents the actual lagged data points, not a time dependent function.</p>
    
    <p name="3818" class="graf graf--p graf-after--p is-selected">Notice that, in equation (3.1), we took the partial derivative of f(t+1) with respect to f(t) and with respect to w(t+1). This partial derivative would result in f(t), which is another function that can be expanded with the 1st order Taylor Series expansion. Interestingly, this would result in the same AR model form, with the only difference being an infinite number of lagged features.</p>
    
    
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*mA6BXcjbLSQGOcqHlfKhfA.png" /> <figcaption></figcaption></figure>
    
    <p name="e2f1" class="graf graf--p graf-after--figure">(3.2) can be reformulated as linear model by replacing the approximation function, f(t), with previous time series values for each lagged time step, i.e., the value of f(t-1) is replaced with y(t-1).</p>
    
    <p name="4643" class="graf graf--p graf-after--p">The final form used to train the autoregressive model is shown in equation (4). The intercept is constrained to be the sum of the autoregressive weights. This allows the model to be unbiased towards a central tendency and to be adaptive over time.</p>
    
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*2uVofzlWJYupcdOmkiCmvQ.png" /> <figcaption></figcaption></figure>
    
    <p name="a9cc" class="graf graf--p graf-after--figure">Where N is the number of data points, T is total number of lagged features, w represents the autoregressive weights, y(t-i) represents the lagged time series, and y*(t+1) is the predicted value at t+1. The objective function, MSE, shown in equation (5), is differentiable with respect to the parameters and can be optimized with TensorFlow.</p>
        
    <p name="7350" class="graf graf--p graf-after--p">Multi-variate time series can be forecasted by applying this same logic. The previous values for all time series are used as covariates to simultaneously predict the next value for all time series. In this case, the intercept is the sum of the output node’s autoregressive weights. The multivariate formulation allows for multiple autoregressive layers to be stacked to create a deep autoregressive model.</p>
    
    
    <h3 name="30b9" class="graf graf--h3 graf-after--p">Daily Minimum Temperature and Rainfall in Melbourne, Australia</h3><p name="88ab" class="graf graf--p graf-after--h3"><a href="https://medium.com/r/?url=https%3A%2F%2Fdatamarket.com%2Fdata%2Fset%2F2324%2Fdaily-minimum-temperatures-in-melbourne-australia-1981-1990%23!ds%3D2324%26display%3Dline" data-href="https://medium.com/r/?url=https%3A%2F%2Fdatamarket.com%2Fdata%2Fset%2F2324%2Fdaily-minimum-temperatures-in-melbourne-australia-1981-1990%23!ds%3D2324%26display%3Dline" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fdatamarket.com%2Fdata%2Fset%2F2324%2Fdaily-minimum-temperatures-in-melbourne-australia-1981-1990%23!ds%3D2324%26display%3Dline" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">Daily Minimum Temperature and Rainfall in Melbourne, Australia</a> dataset was used to build an autoregressive forecasting model. This dataset includes the Temperature and Rainfall across 3625 days, starting in 1981. There were a few missing values, but these values were interpolated for each series. These series were simultaneously forecasted using a deep autoregressive model.</p><h4 name="f656" class="graf graf--h4 graf-after--p">Temperature</h4><p name="1ced" class="graf graf--p graf-after--h4">The plot below shows Temperature in Melbourne across the time frame. There appears to be a clear periodic component to Temperature over time.</p><
        
        <figure><img src="https://cdn-images-1.medium.com/max/1600/1*RVG75eHOabDVoNNrFcMRTw.png" /> <figcaption></figcaption></figure>
        
    
    <h4 name="890b" class="graf graf--h4 graf-after--figure">Rainfall</h4><p name="3e40" class="graf graf--p graf-after--h4">The plot below shows the Rainfall series, in Melbourne across the time frame. Rainfall is clipped at zero centimeters of rain per day which makes it difficult to model using an autoregressive model. In order to use Rainfall, a 60 rolling average for rainfall, shown in the second plot below, was created.</p>
    
    
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*tZU2grJEhaNc_0pstlumlw.png" /> <figcaption></figcaption></figure>
    
    
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*eSTZJUjoq6twOF9nmI1CrQ.png" /> <figcaption></figcaption></figure>

    
    <h4 name="e9b3" class="graf graf--h4 graf-after--figure">Dataset Construction</h4><ol class="postList"><li name="cf5f" class="graf graf--li graf-after--h4">The two series, i.e., Temperature and Rain, were first standardized prior to training.</li><li name="5382" class="graf graf--li graf-after--li">The dataset was constructed by creating 365 lagged features for each observation in the time series. For example, observation 365+1 will have the previous 365*2 features.</li><li name="2487" class="graf graf--li graf-after--li">The first 365 observations were excluded from the training dataset to avoid missing values.</li><li name="7bd2" class="graf graf--li graf-after--li">The last 1,130 observations, or 3 year, for both time series was used as the hold-out set to test the efficacy of the forecasts.</li></ol><h4 name="d76c" class="graf graf--h4 graf-after--li">TensorFlow Formulation</h4><p name="859c" class="graf graf--p graf-after--h4">The code block below shows the TensorFlow code for the autoregressive model formulated above. The example notebook can be found <a href="https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Ffreedomtowin%2Fml-projects%2Fblob%2Fmaster%2Fdeep-autoregressive-model-tensorflow.ipynb" data-href="https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Ffreedomtowin%2Fml-projects%2Fblob%2Fmaster%2Fdeep-autoregressive-model-tensorflow.ipynb" class="markup--anchor markup--p-anchor" rel="noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fgithub.com%2Ffreedomtowin%2Fml-projects%2Fblob%2Fmaster%2Fdeep-autoregressive-model-tensorflow.ipynb" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">here</a>.</p>
    
       <figure><img src="https://cdn-images-1.medium.com/max/1600/1*9T3AM-W3nYSXM_2SA8IeYA.png" /> <figcaption></figcaption></figure>
    
   <p name="3335" class="graf graf--p graf-after--figure">The model has and input of size (N,M), where N is the number of data points and M corresponds to the 730 lagged features for both Rain and Temperature. A hidden layer of size 30 was used with autoregressive activation. The model was trained with stochastic gradient descent, mean squared error loss, an Adam optimizer, early stopping, and a small learning rate. While early stopping was utilized, it might not be necessary since the autoregressive model produces should be inherently regularized.</p><h4 name="306c" class="graf graf--h4 graf-after--p">Snowballed Autoregressive Time&nbsp;Series</h4><p name="296f" class="graf graf--p graf-after--h4">A forecast can be created by snowballing previous predictions into the autoregressive model. The variance of <em class="markup--em markup--p-em">snowballed time series </em>might have the tendency to increase across time, or become unstable, even if the actual time series is stable. A poorly fit model might become unstable and explode in variance across time. Instability can occur if the forecasted <em class="markup--em markup--p-em">snowballed time series </em>is consistently biased above or below the actual trend. The constrained intercept, in the model formulation, should produce more stability and adaptability over time.</p><p name="c267" class="graf graf--p graf-after--p">In order to evaluate forecast stability, the model was trained 100 times on different, random train-validation splits, and 100 models were created. A <em class="markup--em markup--p-em">snowballed time series </em>was generated for each model on the hold-out set. The expected value and the standard deviation were used to create the forecast and confidence intervals, respectively.</p><h4 name="706e" class="graf graf--h4 graf-after--p">Temperature Forecast&nbsp;Result</h4>
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*bi7E-kQX_p8qpLHJez65Zg.png" /> <figcaption></figcaption></figure><h4 name="78f9" class="graf graf--h4 graf-after--figure">Rainfall (60 Rolling Average) Forecast&nbsp;Result</h4>
    <figure><img src="https://cdn-images-1.medium.com/max/1600/1*J9P9xbIQqdDRr6-Oyd_FtA.png" /> <figcaption></figcaption></figure>
    <p name="0dba" class="graf graf--p graf-after--figure">In the plots above, the actual observations, training predictions, and snowballed forecasts are shown by the green, blue, and orange series, respectively. The predicted and forecasted values for Temperature appear to capture the global periodic pattern. However, the variation across time was not captured by the variation across the 100 forecasts. The predicted values for Rainfall (60 rolling average) appear to be overfit on the training dataset. The overfitting might be due to the use of a rolling average feature. The trend&nbsp;, for this series, was accurately captured for ~1 year of forecasted values before collapsing into a periodic pattern. The trend was not accurately captured after ~1 year.</p><h3 name="978f" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="03bd" class="graf graf--p graf-after--h3">The 1st order approximation for the autoregressive function was used to formulate the objective function and the model definition. It was found that the intercept for the autoregressive activation layer was constrained to be the sum of the input’s weights. A deep autoregressive model was created using TensorFlow 2.0 by stacking autoregressive layers. The model was used to simultaneously forecast Temperature and Rainfall in Melbourne AU. The autoregressive formulation did not work with clipped time series, and a rolling average transformation was need to forecast Rainfall. The forecasts were created by snowballing the previous predictions back into the model. Small global trends and periodic patterns appeared to be captured by the model.</p><h3 name="ce7b" class="graf graf--h3 graf-after--p">FB Prophet Forecast Comparison</h3><p name="0fa4" class="graf graf--p graf-after--h3">How does the model stack up against FB Prophet? Prophet is a complete time series forecasting suite with many tunable parameters. For the comparison, I used the out of the box model from the <a href="https://medium.com/r/?url=https%3A%2F%2Ffacebook.github.io%2Fprophet%2Fdocs%2Fquick_start.html%23python-api" data-href="https://medium.com/r/?url=https%3A%2F%2Ffacebook.github.io%2Fprophet%2Fdocs%2Fquick_start.html%23python-api" class="markup--anchor markup--p-anchor" rel="noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ffacebook.github.io%2Fprophet%2Fdocs%2Fquick_start.html%23python-api" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">quick start tutorial</a>.</p><p name="9849" class="graf graf--p graf-after--p">Prophet seems to use a periodogram model. It basically picks out the top periodic frequencies, f, and wraps them in sin and cosine functions to create the feature set, i.e., sin(f) and cos(f). The package also seems to also use the output of a logistic regression model. The logistic regression model predicts whether the series will go up or down. The package seems to support adding additional variables to the forecast, but it doesn’t seem to support simultaneous multi-variate forecasting yet. The comparison was added to the example notebook.</p><h4 name="4a14" class="graf graf--h4 graf-after--p">Temperature Forecast&nbsp;Result</h4>
        <figure><img src="https://cdn-images-1.medium.com/max/1600/1*VgZ_bJ7RoVXXKqDkP1Cwwg.png" /> <figcaption></figcaption></figure>
    <h4 name="e555" class="graf graf--h4 graf-after--figure">Rainfall (60 Rolling Average) Forecast&nbsp;Result</h4>
        <figure><img src="https://cdn-images-1.medium.com/max/1600/1*NBUjnTAjNLxjfTqHxMzxRw.png" /> <figcaption></figcaption></figure>
    <p name="be68" class="graf graf--p graf-after--figure graf--trailing">In the plots above, the actual observations, training predictions, and snowballed forecasts are shown by the green, blue, and orange series, respectively. The predicted and forecasted values for Temperature appear to capture the global periodic pattern. The variation across time was captured by the variation across the 100 forecasts. The trend for Temperature seems to trend upward which may not be the actual trend. The predicted values for Rainfall (60 rolling average) appear to capture a general, yearly periodic pattern. The pattern is consistent throughout the validation. The trend for Rainfall seems to trend downward which may not be the actual trend.</p></div></div></section></div>
